{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Scrapy Installation INSTRUCTIONS ############################################\n",
    "# Open you command terminal (cmd)\n",
    "# write down the following comand: pip install scrapy\n",
    "# wait until the package is installed (it takes time depending on your Internet connection)\n",
    "# To insure that the package is installed successfully, run command: Scrapy version\n",
    "# it should be 1.7 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapy uses a command in terminal to create a project.\n",
    "# still in your terminal (cmd), navigate to the directory where you want to save the project. (i.e. cd command)\n",
    "# to start a project type: scrapy startproject project_name\n",
    "# a new folder with the project_name is now in your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: create a projec that will crawel the web searching for headphones images\n",
    "# in your terminal type: scrapy startproject headphones\n",
    "# Now a folder named 'headphones' is located in your working directory\n",
    "# Now return to your Jupyter notebook and navigate to the headphones folder\n",
    "# under 'headphones-->headphones -->spiders' create a new python3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Run your scraper\n",
    "# Back to your terminal (cmd)\n",
    "# cd headphones\\headphones\\spiders\n",
    "# type the command: scrapy runspider scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## changing output file type\n",
    "# for example, instead of urls.txt, you need a csv file\n",
    "# (1) open settings.py file and add the following 2 lines\n",
    "        ## FEED_FORMAT=\"csv\"\n",
    "        ## FEED_URI=\"urls.csv\"\n",
    "# (2) in your scraper.py change the feeding in the for loop to be in a urls.csv instead of urls.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
